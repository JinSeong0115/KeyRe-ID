import os
import json
import openpifpaf
import numpy as np
import cv2
from PIL import Image

# ì„¤ì •
CONFIDENCE_THRESHOLD = 0.1  # ì‹ ë¢°ë„ ê¸°ì¤€ ì™„í™”
NUM_KEYPOINTS = 17  # COCO keypoints (OpenPifPaf ê¸°ë³¸ í¬ë§·)

# numpy JSON ì§ë ¬í™” ì§€ì›
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)


def preprocess_image(image_path):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬: CLAHE ì ìš© í›„ ì›ë³¸ í•´ìƒë„ ìœ ì§€"""
    try:
        image = Image.open(image_path).convert("RGB")
        image_np = np.array(image, dtype=np.uint8)

        # CLAHE ì ìš© (ëŒ€ë¹„ í–¥ìƒ)
        lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
        cl = clahe.apply(l)
        lab = cv2.merge((cl, a, b))
        image_np = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path} - {e}")
        return None
    return image_np


def extract_keypoints_from_image(img_path, predictor):
    """Keypoint ì¶”ì¶œ (ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜)"""
    image = preprocess_image(img_path)
    if image is None:
        # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ì‹œ keypointsë¥¼ (0,0,0)ìœ¼ë¡œ ì±„ì›€
        return [[0, 0, 0] for _ in range(NUM_KEYPOINTS)], 0.0

    print(f"ğŸ–¼ï¸ Processing image: {img_path}")

    best_keypoints, best_conf = None, 0.0
    for scale in [1.0, 1.2, 1.5]:
        resized_image = cv2.resize(image, (0, 0), fx=scale, fy=scale)
        try:
            predictions, _, _ = predictor.numpy_image(resized_image)
            if predictions:
                keypoints = predictions[0].data.copy()  # ë³µì‚¬í•´ì„œ ìˆ˜ì •
                # ì˜ˆì¸¡ëœ ì¢Œí‘œëŠ” resized_image ì¢Œí‘œ -> ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³´ì •
                keypoints[:, :2] = keypoints[:, :2] / scale

                confidences = keypoints[:, 2]
                avg_conf = confidences.mean() if confidences.size > 0 else 0.0

                if avg_conf > best_conf:
                    best_keypoints, best_conf = keypoints, avg_conf
        except Exception as e:
            print(f"âŒ Prediction failed at scale {scale}: {e}")

    if best_keypoints is None or len(best_keypoints) == 0:
        print(f"âš ï¸ No predictions for {img_path}")
        return [[0, 0, 0] for _ in range(NUM_KEYPOINTS)], 0.0

    # COCO keypointsëŠ” 17ê°œë¥¼ ìš”êµ¬
    keypoints_list = best_keypoints.tolist()
    if len(keypoints_list) < NUM_KEYPOINTS:
        missing_count = NUM_KEYPOINTS - len(keypoints_list)
        keypoints_list += [[0, 0, 0]] * missing_count

    # CONFIDENCE_THRESHOLDë¥¼ ë„˜ëŠ” keypointë§Œ ê³ ë ¤í•˜ì—¬ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    conf_list = [kp[2] for kp in keypoints_list if kp[2] > CONFIDENCE_THRESHOLD]
    avg_conf = np.mean(conf_list) if len(conf_list) > 0 else 0.0
    return keypoints_list[:NUM_KEYPOINTS], avg_conf

def process_mars_dataset(root_dir, output_dir):
    predictor = openpifpaf.Predictor(checkpoint='shufflenetv2k30')

    for phase in ['bbox_train', 'bbox_test']:
        phase_path = os.path.join(root_dir, phase)
        if not os.path.exists(phase_path):
            continue

        # **ìˆœì„œ ë³´ì¥**: í´ë”ëª… ìˆœì°¨ ì •ë ¬
        for person_id in sorted(os.listdir(phase_path)):
            person_path = os.path.join(phase_path, person_id)
            if not os.path.isdir(person_path):
                continue

            keypoints_data = {}
            print(f"ğŸš¶ Processing person: {phase}/{person_id}")

            # **ì´ë¯¸ì§€ íŒŒì¼ë„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬**
            for img_file in sorted(os.listdir(person_path)):
                if img_file.endswith('.jpg'):
                    img_path = os.path.join(person_path, img_file)
                    keypoints, avg_conf = extract_keypoints_from_image(img_path, predictor)

                    # Keypoint ê²°ê³¼ ì €ì¥
                    keypoints_data[img_file] = {
                        "keypoints": keypoints,
                        "avg_confidence": float(avg_conf)
                    }

            # ê²°ê³¼ ì €ì¥
            save_dir = os.path.join(output_dir, phase, person_id)
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, "keypoints.json")
            with open(save_path, 'w') as f:
                json.dump(keypoints_data, f, indent=4, cls=NumpyEncoder)

            print(f"âœ… Keypoints saved: {save_path}")


if __name__ == '__main__':
    dataset_root = '/home/user/kim_js/ReID/dataset/MARS'
    output_root = '/home/user/kim_js/ReID/dataset/MARS/keypoint'
    process_mars_dataset(dataset_root, output_root)
